site_name: "FusionBench"

nav:
  - Home: README.md
  - Fusion Algorithms:
      - Introduction: algorithms/README.md
      - Dummy: algorithms/dummy.md
      - Model Ensemble: 
        - Simple Ensemble: algorithms/simple_ensemble.md
        - Weighted Ensemble: algorithms/weighted_ensemble.md
        - Max-Model Predictor: algorithms/max-model_predictor.md
        # - Model Specification: algorithms/specification_ensemble.md
      - Model Merging:
        - Simple Averaging: algorithms/simple_averaging.md
        - Weighted Averaging: algorithms/weighted_averaging.md
        - Fisher Merging: algorithms/fisher_merging.md
        - Task Arithmetic: algorithms/task_arithmetic.md
        - Ties-Merging: algorithms/ties_merging.md
        - AdaMerging: algorithms/adamerging.md
        - RegMean: algorithms/regmean.md
        - Concrete Subspace: algorithms/concrete_subspace.md
      - Model Mixing:
        - Depth Upscaling: algorithms/depth_upscaling.md
        - MoE-based Upscaling: algorithms/moe_based_upscaling.md
        - MoE-based Merging: algorithms/moe_based_merging.md
        - Weight-Ensembling MoE: algorithms/weight_ensembling_moe.md
        # - Model Stitching: algorithms/model_stitching.md
        - Model Recombination: algorithms/model_recombination.md
  - Model Pool (Benchmark):
      - Introduction: modelpool/README.md
      - CLIP-ViT Models: modelpool/clip_vit.md
      - ResNet Models for Sence Understanding: modelpool/nyuv2.md
      - GPT-2 Models for Text Classification: modelpool/gpt2_classification.md
      - Flan-T5 Models for Text Generation: modelpool/flan-t5_generation.md
  - Task Pool (Evaluation):
      - Introduction: taskpool/README.md
      - Dummy: taskpool/dummy.md
      - Classification Tasks for CLIP: taskpool/clip_vit_classification.md
      - GPT-2 Sequence Classification Tasks: taskpool/gpt2_classification.md
      - Flan-T5 Models for Text Generation: taskpool/flan-t5_generation.md
  - Command Line Interface:
    - fusion_bench: cli/fusion_bench.md
  - Programming Guides:
    - CLIP-ViT Models For Image Classification:
      - Manage Labels and Templates: guides/clip_vit/classification_templates.md
  - Reading Lists: readinglist/README.md

plugins:
  - search
  - autorefs
  - mkdocstrings:
      enabled: !ENV [ENABLE_MKDOCSTRINGS, true]
      default_handler: python
      handlers:
        python:
          options:
            show_source: true
            show_root_heading: true
            show_root_toc_entry: false
            show_root_full_path: false
            show_root_members_full_path: false
            show_object_full_path: false
            group_by_category: true
            show_submodules: true
            parameter_headings: true
            show_bases: true
            docstring_section_style: list
            show_symbol_type_heading: true
            show_symbol_type_toc: true
            heading_level: 4

markdown_extensions:
  - attr_list
  - md_in_html
  - toc:
      permalink: true
      toc_depth: 6
  - pymdownx.highlight:
      anchor_linenums: true
      line_spans: __span
      pygments_lang_class: true
  - pymdownx.inlinehilite
  - pymdownx.snippets
  - admonition
  - pymdownx.details
  - pymdownx.superfences
  - pymdownx.arithmatex:
      generic: true
  - tables
  - footnotes
  - pymdownx.tabbed:
      alternate_style: true
  - pymdownx.emoji:
      emoji_index: !!python/name:material.extensions.emoji.twemoji
      emoji_generator: !!python/name:material.extensions.emoji.to_svg

extra_javascript:
  - javascripts/mathjax.js
  - https://polyfill.io/v3/polyfill.min.js?features=es6
  - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js
extra_css:
  - css/mkdocstrings.css
  - css/material_extra.css
theme:
  name: material
  features:
    - toc.follow
    - content.code.annotate

repo_url: https://github.com/tanganke/fusion_bench

