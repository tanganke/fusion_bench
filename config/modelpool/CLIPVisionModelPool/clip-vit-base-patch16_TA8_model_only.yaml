defaults:
  - CLIPVisionModelPool@: _template
  - /model/clip-vit@models: clip-vit-base-patch16_eight_tasks
processor:
  _target_: transformers.CLIPProcessor.from_pretrained
  pretrained_model_name_or_path: openai/clip-vit-base-patch16
