defaults:
  - CLIPVisionModelPool@: _template
  - /model/clip-vit@models:
      - clip-vit-base-patch16
processor:
  _target_: transformers.CLIPProcessor.from_pretrained
  pretrained_model_name_or_path: openai/clip-vit-base-patch16
