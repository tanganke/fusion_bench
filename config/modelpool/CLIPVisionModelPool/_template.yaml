_usage_: |
  defaults:
    - CLIPVisionModelPool@: _template
_target_: fusion_bench.modelpool.CLIPVisionModelPool
_version_: "0.2"
_recursive_: False
models: ???
train_datasets: null
test_datasets: null
processor:
  _target_: transformers.CLIPProcessor.from_pretrained
  # pretrained_model_name_or_path: openai/clip-vit-base-patch32
  pretrained_model_name_or_path: /home/htl/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268
