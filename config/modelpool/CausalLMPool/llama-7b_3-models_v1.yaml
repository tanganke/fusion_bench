_target_: fusion_bench.modelpool.CausalLMPool
_recursive_: false
enable_lazy_loading: true
models:
  _pretrained_: meta-llama/Llama-2-7b-hf
  chat: meta-llama/Llama-2-7b-chat-hf
  math: WizardLMTeam/WizardMath-7B-V1.0
  code: codellama/CodeLlama-7b-hf
model_kwargs:
  torch_dtype: bfloat16
tokenizer: meta-llama/Llama-2-7b-hf
