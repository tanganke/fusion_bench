_target_: fusion_bench.modelpool.CLIPVisionModelPool
base_model: openai/clip-vit-base-patch32
models:
  _pretrained_:
    _target_: transformers.CLIPVisionModel.from_pretrained
    pretrained_model_name_or_path: ${...base_model}
train_datasets:
  svhn:
    _target_: datasets.load_dataset
    _args_:
      - svhn
      - cropped_digits
    split: train
processor:
  _target_: transformers.CLIPProcessor.from_pretrained
  pretrained_model_name_or_path: ${..base_model}
